{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1h/16SlnqPCqP+MG4Ru7G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shreyanshd23/Cedit-Card-Fraud-Detection/blob/main/Credit-Card-Anomaly-Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QuElaRcz1A0",
        "outputId": "7c433c7c-376f-4663-c1ac-655da27f7d62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean vector shape: (28,)\n",
            "Covariance matrix shape: (28, 28)\n",
            "Epsilon (0.5 percentile): 9.66828319e-162\n",
            "F1 Score: 0.5122\n",
            "Sample Probabilities: [2.28986240e-12 1.26509168e-11 6.12478790e-19 9.10199169e-15\n",
            " 8.02932820e-13 1.84216021e-11 3.97771554e-12 4.01397628e-22\n",
            " 3.22633751e-14 4.93935243e-12]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "from scipy.stats import multivariate_normal\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/creditcard.csv')\n",
        "\n",
        "# Use all PCA features (V1 to V28) and 'Amount'\n",
        "features = [f'V{i}' for i in range(1, 29)] #+  ['Amount']\n",
        "\n",
        "# Ensure all feature columns are numeric and handle errors\n",
        "df[features] = df[features].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Also ensure 'Class' column is numeric\n",
        "df['Class'] = pd.to_numeric(df['Class'], errors='coerce')\n",
        "\n",
        "# Drop any rows where 'Class' is NaN (important!)\n",
        "df = df.dropna(subset=['Class'])\n",
        "\n",
        "# Deal with any NaN values in features\n",
        "df[features] = df[features].fillna(df[features].median())\n",
        "\n",
        "X = df[features].values\n",
        "y = df['Class'].values.astype(int)  # Make sure y is integer type\n",
        "\n",
        "# Fit multivariate Gaussian on normal data (Class == 0)\n",
        "X_normal = X[y == 0]\n",
        "mu = X_normal.mean(axis=0)\n",
        "cov = np.cov(X_normal, rowvar=False)\n",
        "\n",
        "# Compute probability density for all data points\n",
        "rv = multivariate_normal(mean=mu, cov=cov, allow_singular=True)\n",
        "probs = rv.pdf(X)\n",
        "\n",
        "epsilon = np.percentile(probs, 0.3)\n",
        "preds = (probs < epsilon).astype(int)\n",
        "\n",
        "f1 = f1_score(y, preds)\n",
        "\n",
        "print(f\"Mean vector shape: {mu.shape}\")\n",
        "print(f\"Covariance matrix shape: {cov.shape}\")\n",
        "print(f\"Epsilon (0.5 percentile): {epsilon:.8e}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(\"Sample Probabilities:\", probs[:10])"
      ]
    }
  ]
}